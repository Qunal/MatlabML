
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>Load Forecasting using Bagged Regression Trees</title><meta name="generator" content="MATLAB 7.14"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2012-05-04"><meta name="DC.source" content="LoadScriptTrees_aus.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img { margin-bottom:0px; } 

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, tt, code { font-size:12px; }
pre { margin:0px 0px 20px; }
pre.error { color:red; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }

  </style></head><body><div class="content"><h1>Load Forecasting using Bagged Regression Trees</h1><!--introduction--><p>This example demonstrates an alternate model for building relationships between historical weather and load data to build and test a short term load forecasting. The model used is a set of aggregated Regression Trees.</p><!--/introduction--><h2>Contents</h2><div><ul><li><a href="#1">Import Data</a></li><li><a href="#3">Generate Predictor Matrix</a></li><li><a href="#4">Split the dataset to create a Training and Test set</a></li><li><a href="#5">Build the Bootstrap Aggregated Regression Trees</a></li><li><a href="#6">Determine Feature Importance</a></li><li><a href="#7">Build the Final Model</a></li><li><a href="#8">Save Trained Model</a></li><li><a href="#9">Test Results</a></li><li><a href="#10">Compute Prediction</a></li><li><a href="#11">Compare Forecasted Load and Actual Load</a></li><li><a href="#12">Compute Model Forecast Metrics</a></li></ul></div><h2>Import Data<a name="1"></a></h2><p>The data set used is a table of historical hourly loads and temperature observations from the AEMO &amp; BOM for Sydney/NSW for the years 2006 to 2010. The weather information includes the dry bulb, wet bulb temperatures dew point &amp; humidity</p><pre class="codeinput">load <span class="string">ausdata</span>
</pre><p>Import list of holidays</p><pre class="codeinput">[num, text] = xlsread(<span class="string">'..\Data\Holidays2.xls'</span>);
holidays = text(2:end,1);
</pre><h2>Generate Predictor Matrix<a name="3"></a></h2><p>The function <b>genPredictors</b> generates the predictor variables used as inputs for the model. For short-term forecasting these include</p><div><ul><li>Dry bulb temperature</li><li>Dew point</li><li>Wet bulb temperature</li><li>Humidity</li><li>Hour of day</li><li>Day of the week</li><li>A flag indicating if it is a holiday/weekend</li><li>Previous day's average load</li><li>Demand from the same hour the previous day</li><li>Demand from the same hour and same day from the previous week</li></ul></div><p>If the goal is medium-term or long-term load forecasting, only the inputs hour of day, day of week, time of year and holidays can be used deterministically. The weather/load information would need to be specified as an average or a distribution</p><pre class="codeinput"><span class="comment">% Select forecast horizon</span>
term = <span class="string">'short'</span>;

[X, dates, labels] = genPredictors2(data, term, holidays);
</pre><h2>Split the dataset to create a Training and Test set<a name="4"></a></h2><p>The dataset is divided into two sets, a <i>training</i> set which includes data from 2004 to 2007 and a <i>test</i> set with data from 2008. The training set is used for building the model (estimating its parameters). The test set is used only for forecasting to test the performance of the model on out-of-sample data.</p><pre class="codeinput"><span class="comment">% Create training set</span>
trainInd = data.NumDate &lt; datenum(<span class="string">'20010-01-01'</span>);
trainX = X(trainInd,:);
trainY = data.SYSLoad(trainInd);

<span class="comment">% Create test set and save for later</span>
testInd = data.NumDate &gt;= datenum(<span class="string">'2010-01-01'</span>);
testX = X(testInd,:);
testY = data.SYSLoad(testInd);
testDates = dates(testInd);

save <span class="string">Data\testSet_aus</span> <span class="string">testDates</span> <span class="string">testX</span> <span class="string">testY</span>
clear <span class="string">X</span> <span class="string">data</span> <span class="string">trainInd</span> <span class="string">testInd</span> <span class="string">term</span> <span class="string">holidays</span> <span class="string">dates</span> <span class="string">ans</span>
</pre><h2>Build the Bootstrap Aggregated Regression Trees<a name="5"></a></h2><p>The function TreeBagger is used to build the model, ie. a set of regression trees each with a different set of rules for performing the non-linear regression. We initially start by building an aggregate of 20 such trees, with a minimum leaf size of 40. The larger the leaf size the smaller the tree. This provides a control for overfitting and performance.</p><pre class="codeinput">model = TreeBagger(20, trainX, trainY, <span class="string">'method'</span>, <span class="string">'regression'</span>, <span class="string">'minleaf'</span>, 40)

simpleTree = prune(model.Trees{1}, 1330);
view(simpleTree, <span class="string">'names'</span>, labels);
</pre><pre class="codeoutput">model = 
Ensemble with 20 bagged decision trees:
               Training X:           [87648x10]
               Training Y:            [87648x1]
                   Method:           regression
                    Nvars:                   10
             NVarToSample:                    4
                  MinLeaf:                   40
                    FBoot:                    1
    SampleWithReplacement:                    1
     ComputeOOBPrediction:                    0
         ComputeOOBVarImp:                    0
                Proximity:                   []
</pre><img vspace="5" hspace="5" src="LoadScriptTrees_aus_01.png" alt=""> <h2>Determine Feature Importance<a name="6"></a></h2><p>Of each of the predictors, which ones provide the most predictive power? Turning on the <i>oobVarImp</i> parameter shows you out-of-bag estimates of this relative feature (input) importance.</p><pre class="codeinput">model = TreeBagger(20, trainX, trainY, <span class="string">'method'</span>, <span class="string">'regression'</span>, <span class="keyword">...</span>
                   <span class="string">'oobvarimp'</span>, <span class="string">'on'</span>, <span class="string">'minleaf'</span>, 30);

figure(2);
barh(model.OOBPermutedVarDeltaError);
ylabel(<span class="string">'Feature'</span>);
xlabel(<span class="string">'Out-of-bag feature importance'</span>);
title(<span class="string">'Feature importance results'</span>);
set(gca, <span class="string">'YTickLabel'</span>, labels)
</pre><img vspace="5" hspace="5" src="LoadScriptTrees_aus_02.png" alt=""> <h2>Build the Final Model<a name="7"></a></h2><p>Given our analysis of parameters, we may wish to now build the final model with 20 trees, a leaf size of 20 and all of the features</p><pre class="codeinput">model = TreeBagger(20, trainX, trainY, <span class="string">'method'</span>, <span class="string">'regression'</span>, <span class="string">'minleaf'</span>, 20);
</pre><h2>Save Trained Model<a name="8"></a></h2><p>We can compact the model (to remove any stored training data) and save for later reuse</p><pre class="codeinput">model = compact(model);
save <span class="string">Models\TreeModel_aus</span> <span class="string">model</span>
</pre><h2>Test Results<a name="9"></a></h2><p>Load in the model and test data and run the treeBagger forecaster and compare to actual load.</p><pre class="codeinput">clear
cd <span class="string">Models</span>
load <span class="string">Models\TreeModel_aus</span>
cd <span class="string">..</span>
cd <span class="string">Data</span>
load <span class="string">Data\testSet_aus</span>
cd <span class="string">..</span>
</pre><h2>Compute Prediction<a name="10"></a></h2><p>Predict the load for 2008 using the model trained on load data from 2007 and before.</p><pre class="codeinput">forecastLoad = predict(model, testX);
</pre><h2>Compare Forecasted Load and Actual Load<a name="11"></a></h2><p>Create a plot to compare the actual load and the predicted load as well as the forecast error.</p><pre class="codeinput">ax1 = subplot(2,1,1);
plot(testDates, [testY forecastLoad]);
ylabel(<span class="string">'Load'</span>); legend({<span class="string">'Actual'</span>, <span class="string">'Forecast'</span>}); legend(<span class="string">'boxoff'</span>)
ax2 = subplot(2,1,2);
plot(testDates, testY-forecastLoad);
xlabel(<span class="string">'Date'</span>); ylabel(<span class="string">'Error (MWh)'</span>);
linkaxes([ax1 ax2], <span class="string">'x'</span>);
dynamicDateTicks([ax1 ax2], <span class="string">'linked'</span>)
</pre><pre class="codeoutput">Undefined function 'dynamicDateTicks' for input arguments of type 'double'.
Error in LoadScriptTrees_aus (line 133)
dynamicDateTicks([ax1 ax2], 'linked')</pre><h2>Compute Model Forecast Metrics<a name="12"></a></h2><p>In addition to the visualization we can quantify the performance of the forecaster using metrics such as mean average error (MAE), mean average percent error (MAPE) and daily peak forecast error.</p><pre class="codeinput">err = testY-forecastLoad;
errpct = abs(err)./testY*100;


fL = reshape(forecastLoad(1:end-1), 48, (length(forecastLoad)-1)/48)';
tY = reshape(testY(1:end-1), 48, (length(testY)-1)/48)';

peakerrpct = abs(max(tY,[],2) - max(fL,[],2))./max(tY,[],2) * 100;

fprintf(<span class="string">'Mean Average Percent Error (MAPE): %0.2f%% \nMean Average Error (MAE): %0.2f MWh\nDaily Peak MAPE: %0.2f%%\n'</span>,<span class="keyword">...</span>
    mean(errpct(~isinf(errpct))), mean(abs(err)), mean(peakerrpct))
</pre><p class="footer"><br>
      Published with MATLAB&reg; 7.14<br></p></div><!--
##### SOURCE BEGIN #####
%% Load Forecasting using Bagged Regression Trees
% This example demonstrates an alternate model for building relationships
% between historical weather and load data to build and test a short term
% load forecasting. The model used is a set of aggregated Regression Trees.

%% Import Data
% The data set used is a table of historical hourly loads and temperature
% observations from the AEMO & BOM for Sydney/NSW for the years 2006 to 2010. The
% weather information includes the dry bulb, wet bulb temperatures dew
% point & humidity

load ausdata
%%
% Import list of holidays
[num, text] = xlsread('..\Data\Holidays2.xls');
holidays = text(2:end,1);


%% Generate Predictor Matrix
% The function *genPredictors* generates the predictor variables used as
% inputs for the model. For short-term forecasting these include
% 
% * Dry bulb temperature
% * Dew point
% * Wet bulb temperature
% * Humidity
% * Hour of day
% * Day of the week
% * A flag indicating if it is a holiday/weekend
% * Previous day's average load
% * Demand from the same hour the previous day
% * Demand from the same hour and same day from the previous week
%
% If the goal is medium-term or long-term load forecasting, only the inputs
% hour of day, day of week, time of year and holidays can be used
% deterministically. The weather/load information would need to be
% specified as an average or a distribution

% Select forecast horizon
term = 'short';

[X, dates, labels] = genPredictors2(data, term, holidays);

%% Split the dataset to create a Training and Test set
% The dataset is divided into two sets, a _training_ set which includes 
% data from 2004 to 2007 and a _test_ set with data from 2008. The training
% set is used for building the model (estimating its parameters). The test
% set is used only for forecasting to test the performance of the model on 
% out-of-sample data. 

% Create training set
trainInd = data.NumDate < datenum('20010-01-01');
trainX = X(trainInd,:);
trainY = data.SYSLoad(trainInd);

% Create test set and save for later
testInd = data.NumDate >= datenum('2010-01-01');
testX = X(testInd,:);
testY = data.SYSLoad(testInd);
testDates = dates(testInd);

save Data\testSet_aus testDates testX testY
clear X data trainInd testInd term holidays dates ans
%% Build the Bootstrap Aggregated Regression Trees
% The function TreeBagger is used to build the model, ie. a set of regression
% trees each with a different set of rules for performing the non-linear regression.
% We initially start by building an aggregate of 20 such trees, with a
% minimum leaf size of 40. The larger the leaf size the smaller the tree.
% This provides a control for overfitting and performance.

model = TreeBagger(20, trainX, trainY, 'method', 'regression', 'minleaf', 40)

simpleTree = prune(model.Trees{1}, 1330);
view(simpleTree, 'names', labels);

%% Determine Feature Importance
% Of each of the predictors, which ones provide the most predictive power?
% Turning on the _oobVarImp_ parameter shows you out-of-bag estimates of this
% relative feature (input) importance. 

model = TreeBagger(20, trainX, trainY, 'method', 'regression', ...
                   'oobvarimp', 'on', 'minleaf', 30);

figure(2);
barh(model.OOBPermutedVarDeltaError);
ylabel('Feature');
xlabel('Out-of-bag feature importance');
title('Feature importance results');
set(gca, 'YTickLabel', labels)

%% Build the Final Model
% Given our analysis of parameters, we may wish to now build the final
% model with 20 trees, a leaf size of 20 and all of the features

model = TreeBagger(20, trainX, trainY, 'method', 'regression', 'minleaf', 20);

%% Save Trained Model
% We can compact the model (to remove any stored training data) and save
% for later reuse

model = compact(model);
save Models\TreeModel_aus model


%% Test Results
% Load in the model and test data and run the treeBagger forecaster and
% compare to actual load.

clear
cd Models
load Models\TreeModel_aus
cd ..
cd Data
load Data\testSet_aus
cd ..

%% Compute Prediction
% Predict the load for 2008 using the model trained on load data from 2007
% and before.
forecastLoad = predict(model, testX);

%% Compare Forecasted Load and Actual Load
% Create a plot to compare the actual load and the predicted load as well
% as the forecast error.

ax1 = subplot(2,1,1);
plot(testDates, [testY forecastLoad]);
ylabel('Load'); legend({'Actual', 'Forecast'}); legend('boxoff')
ax2 = subplot(2,1,2);
plot(testDates, testY-forecastLoad);
xlabel('Date'); ylabel('Error (MWh)');
linkaxes([ax1 ax2], 'x');
dynamicDateTicks([ax1 ax2], 'linked')

%% Compute Model Forecast Metrics
% In addition to the visualization we can quantify the performance of the
% forecaster using metrics such as mean average error (MAE), mean average
% percent error (MAPE) and daily peak forecast error.

err = testY-forecastLoad;
errpct = abs(err)./testY*100;


fL = reshape(forecastLoad(1:end-1), 48, (length(forecastLoad)-1)/48)';
tY = reshape(testY(1:end-1), 48, (length(testY)-1)/48)';

peakerrpct = abs(max(tY,[],2) - max(fL,[],2))./max(tY,[],2) * 100;

fprintf('Mean Average Percent Error (MAPE): %0.2f%% \nMean Average Error (MAE): %0.2f MWh\nDaily Peak MAPE: %0.2f%%\n',...
    mean(errpct(~isinf(errpct))), mean(abs(err)), mean(peakerrpct))
##### SOURCE END #####
--></body></html>